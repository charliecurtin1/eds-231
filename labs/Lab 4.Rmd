---
title: "Lab 4"
author: "Charlie Curtin"
date: "2024-04-24"
output: html_document
---

Lab 4 Assignment: Due May 7 at 11:59pm

1. Select another classification algorithm.  

2. Conduct an initial out-of-the-box model fit on the training data and prediction on the test data.  Assess the performance of this initial model. 

3. Select the relevant hyperparameters for your algorithm and tune your model.

4. Conduct a model fit using your newly tuned model specification.  How does it compare to your out-of-the-box model?

5.
  a. Use variable importance to determine the terms most highly associated with non-fatal reports?  What about terms associated with fatal reports? OR
  b. If you aren't able to get at variable importance with your selected algorithm, instead tell me how you might in theory be able to do it. Or how you might determine the important distinguishing words in some other way. 

6. Predict fatality of the reports in the test set.  Compare this prediction performance to that of the Naive Bayes and Lasso models.  Why do you think your model performed as it did, relative to the other two?

```{r packages, include = FALSE, message = FALSE}
library(tidytext)
library(tidyverse)
library(tidymodels)
library(textrecipes)
library(ranger)
```

```{r, message = FALSE}
# load climbing accidents data
urlfile ="https://raw.githubusercontent.com/MaRo406/EDS-231-text-sentiment/main/data/climbing_reports_model_dat.csv"

incidents_df<-readr::read_csv(url(urlfile))

## split into training and testing data
set.seed(1234)

# turn the fatal binary into classes
incidents2class <- incidents_df %>%
  mutate(fatal = factor(if_else(
                        is.na(Deadly),
                        "non-fatal", "fatal")))


incidents_split <- initial_split(incidents2class, strata = fatal)

incidents_train <- training(incidents_split)
incidents_test <- testing(incidents_split)
```

```{r}
# specify a recipe to predict fatalities based on the text
incidents_rec <- recipe(fatal ~ Text, data = incidents_train)

# add preprocessing steps
recipe <- incidents_rec %>%
  # create word tokens based on the contents of text
  step_tokenize(Text) %>%
  # filter to the most common words
  step_tokenfilter(Text, max_tokens = 1000) %>%
  # calculate the tf-idf
  step_tfidf(Text)

# bundle the recipe into a workflow
incidents_wf <- workflow() %>%
  add_recipe(recipe)

# specify a random forest as our choseb model
rf_spec <- rand_forest() %>%
  set_engine("ranger") %>%
  set_mode("classification")
```