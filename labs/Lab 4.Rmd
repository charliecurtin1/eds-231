---
title: "Lab 4"
author: "Charlie Curtin"
date: "2024-04-24"
output: html_document
---

Lab 4 Assignment: Due May 7 at 11:59pm

1. Select another classification algorithm.  

2. Conduct an initial out-of-the-box model fit on the training data and prediction on the test data.  Assess the performance of this initial model. 

3. Select the relevant hyperparameters for your algorithm and tune your model.

4. Conduct a model fit using your newly tuned model specification.  How does it compare to your out-of-the-box model?

5.
  a. Use variable importance to determine the terms most highly associated with non-fatal reports?  What about terms associated with fatal reports? OR
  b. If you aren't able to get at variable importance with your selected algorithm, instead tell me how you might in theory be able to do it. Or how you might determine the important distinguishing words in some other way. 

6. Predict fatality of the reports in the test set.  Compare this prediction performance to that of the Naive Bayes and Lasso models.  Why do you think your model performed as it did, relative to the other two?

```{r packages, include = FALSE, message = FALSE}
library(tidytext)
library(tidyverse)
library(tidymodels)
library(textrecipes)
library(ranger)
```

```{r, message = FALSE}
# load climbing accidents data
urlfile ="https://raw.githubusercontent.com/MaRo406/EDS-231-text-sentiment/main/data/climbing_reports_model_dat.csv"

incidents_df<-readr::read_csv(url(urlfile))

## split into training and testing data
set.seed(1234)

# turn the fatal binary into classes
incidents2class <- incidents_df %>%
  mutate(fatal = factor(if_else(
                        is.na(Deadly),
                        "non-fatal", "fatal")))


incidents_split <- initial_split(incidents2class, strata = fatal)

incidents_train <- training(incidents_split)
incidents_test <- testing(incidents_split)

# create folds for k-folds cross-validation
incidents_folds <- vfold_cv(incidents_train)

```

```{r}
# specify a recipe to predict fatalities based on the text
incidents_rec <- recipe(fatal ~ Text, data = incidents_train)

# add preprocessing steps
recipe <- incidents_rec %>%
  # create word tokens based on the contents of text
  step_tokenize(Text) %>%
  # filter to the most common words
  step_tokenfilter(Text, max_tokens = 1000) %>%
  # calculate the tf-idf
  step_tfidf(Text)

# specify a random forest as our chosen model
rf_spec <- rand_forest() %>%
  set_engine("ranger") %>%
  set_mode("classification")

# bundle our model spec and recipe into a workflow
rf_wf <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(rf_spec)

# estimate performance with resampling
rf_rs <- fit_resamples(
  rf_wf, 
  incidents_folds, 
  control = control_resamples(save_pred = TRUE)
)

# collect performance metrics and predictions
rf_rs_metrics <- collect_metrics(rf_rs)
rf_rs_predictions <- collect_predictions(rf_rs)

rf_rs_metrics

# graph the roc auc curve for the random forest classification model
rf_rs_predictions %>%
  group_by(id) %>%
  roc_curve(truth = fatal, .pred_fatal) %>%
  autoplot() +
  labs(title = "ROC curve for Climbing Incident Reports")

# or a confusion matrix
conf_mat_resampled(rf_rs, tidy = FALSE) %>%
  autoplot(type = "heatmap")
```